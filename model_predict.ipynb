{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model_predict",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/p2E9ORV0ti9PyXxTKfU+"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlHrlH35MO4p"
      },
      "source": [
        "Read model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_teWB84vMOtv",
        "outputId": "c5d42086-8329-478a-b902-0b21027ea804"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2nCfE0WV6cv"
      },
      "source": [
        "Get test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeUNLOeKV9Kf"
      },
      "source": [
        "!wget \"https://putpoznanpl-my.sharepoint.com/:u:/g/personal/dominik_pieczynski_put_poznan_pl/EWIZ_xm8wXpMjQDgF2VQ1csB4QuHPKoj5vDpj6CQi9p-AA?e=yQr6fn&download=1\" -O public.zip\n",
        "!unzip -q public.zip\n",
        "!rm public.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EneAPAvU38a"
      },
      "source": [
        "Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MF-DpIqVTj-"
      },
      "source": [
        "!pip install segmentation_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N-m61lMRXfe"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import segmentation_models\n",
        "# import segmentation_models.metrics\n",
        "from segmentation_models.losses import dice_loss\n",
        "\n",
        "# model = create_model()\n",
        "\n",
        "model_path = '/content/drive/MyDrive/ZPO_projekt/models/model_19'\n",
        "\n",
        "\n",
        "dice_score = segmentation_models.metrics.FScore(threshold=0.5)\n",
        "\n",
        "model = keras.models.load_model(model_path, custom_objects={\"f1-score\": dice_score, \"dice_loss\": dice_loss})"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tz38TO1TBHW",
        "outputId": "b6f12824-db7d-4222-c154-6c8a0f59ee11"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Model1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, None, None, 1)]   0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, None, None, 3)     6         \n",
            "_________________________________________________________________\n",
            "model (Functional)           (None, None, None, 1)     12641169  \n",
            "=================================================================\n",
            "Total params: 12,641,175\n",
            "Trainable params: 12,577,143\n",
            "Non-trainable params: 64,032\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSIg5pe9XwiU"
      },
      "source": [
        "!mkdir /content/predictions"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyajWKZhX2kg"
      },
      "source": [
        "!mkdir /content/predictions/first\n",
        "!mkdir /content/predictions/second"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uMAD3pUgXGV"
      },
      "source": [
        "!pip install --upgrade nibabel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aivVCBAuatls"
      },
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "\n",
        "from typing import Tuple, List\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def load_raw_volume(path: Path) -> Tuple[np.ndarray, np.ndarray]:\n",
        "  data: nib.Nifti1Image = nib.load(str(path))\n",
        "  data = nib.as_closest_canonical(data)\n",
        "  raw_data = data.get_fdata(caching='unchanged', dtype=np.float32)\n",
        "  return raw_data, data.affine\n",
        "\n",
        "\n",
        "def load_labels_volume(path: Path) -> np.ndarray:\n",
        "  return load_raw_volume(path)[0].astype(np.uint8)\n",
        "\n",
        "\n",
        "def save_labels(data: np.ndarray, affine: np.ndarray, path: Path):\n",
        "  nib.save(nib.Nifti1Image(data, affine), str(path))\n",
        "\n",
        "\n",
        "def show_slices(slices: List[np.ndarray]):\n",
        "   fig, axes = plt.subplots(1, len(slices))\n",
        "   for i, data_slice in enumerate(slices):\n",
        "       axes[i].imshow(data_slice.T, cmap=\"gray\", origin=\"lower\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "250hdvu1kYR_"
      },
      "source": [
        "from pathlib import Path\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "first_dataset_path = Path('/content/FirstDataset/test')\n",
        "second_dataset_path = Path('/content/SecondDataset/test')\n",
        "predictions_base_path = Path('/content/predictions')\n",
        "first_dataset_predictions_path = predictions_base_path / 'first'\n",
        "second_dataset_predictions_path = predictions_base_path / 'second'\n",
        "\n",
        "counter = 1\n",
        "for scan_path in first_dataset_path.iterdir():\n",
        "  print(counter)\n",
        "  counter += 1\n",
        "\n",
        "  data, affine = load_raw_volume(scan_path)\n",
        "  labels = np.zeros(data.shape, dtype=np.uint8)\n",
        "\n",
        "  data_max=np.amax(data)\n",
        "  data_min=np.amin(data)\n",
        "\n",
        "  x_size, y_size, z_size = data.shape\n",
        "  for x_index in range(x_size):\n",
        "    data_slice = data[x_index]\n",
        "\n",
        "    data_slice = (data_slice - data_min)/(data_max - data_min)\n",
        "\n",
        "    data_slice = cv2.resize(data_slice, (128, 128))\n",
        "    data_slice = data_slice[...,np.newaxis]\n",
        "    data_slice = data_slice[np.newaxis,...]\n",
        "\n",
        "    prediction = model.predict(data_slice)\n",
        "    prediction = prediction.squeeze()\n",
        "\n",
        "    prediction[prediction<0.05]=0\n",
        "    prediction[prediction>=0.05]=1\n",
        "\n",
        "    # plt.imshow(prediction)\n",
        "    # plt.show()\n",
        "    \n",
        "    prediction = cv2.resize(prediction,(z_size,y_size))\n",
        "\n",
        "    labels[x_index] = prediction\n",
        "\n",
        "  save_labels(labels, affine, first_dataset_predictions_path / scan_path.name)\n",
        "\n",
        "# ----------------------------------------------\n",
        "counter = 1 \n",
        "for scan_path in second_dataset_path.iterdir():\n",
        "  print(counter)\n",
        "  counter += 1\n",
        "\n",
        "  data, affine = load_raw_volume(scan_path / 'T1w.nii.gz')\n",
        "  labels = np.zeros(data.shape, dtype=np.uint8)\n",
        "  \n",
        "  data_max=np.amax(data)\n",
        "  data_min=np.amin(data)\n",
        "\n",
        "  x_size, y_size, z_size = data.shape\n",
        "  for x_index in range(x_size):\n",
        "    data_slice = data[x_index]\n",
        "\n",
        "    data_slice = (data_slice - data_min)/(data_max - data_min)\n",
        "\n",
        "    data_slice = cv2.resize(data_slice, (128, 128))\n",
        "    data_slice = data_slice[...,np.newaxis]\n",
        "    data_slice = data_slice[np.newaxis,...]\n",
        "    prediction = model.predict(data_slice)\n",
        "    prediction = prediction.squeeze()\n",
        "\n",
        "    prediction[prediction<0.05]=0\n",
        "    prediction[prediction>=0.05]=1\n",
        "\n",
        "    # plt.imshow(prediction)\n",
        "    # plt.show()\n",
        "\n",
        "    prediction = cv2.resize(prediction,(z_size,y_size))\n",
        "\n",
        "    labels[x_index] = prediction\n",
        "  \n",
        "  save_labels(labels, affine, second_dataset_predictions_path / f'{scan_path.name}.nii.gz')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FOHSbH-pSsg"
      },
      "source": [
        "Save predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juOmkBy3pWVm"
      },
      "source": [
        "!zip -r predictions.zip /content/predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igi5i-34pSG8"
      },
      "source": [
        "!cp /content/predictions.zip -r /content/drive/MyDrive/ZPO_projekt"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}